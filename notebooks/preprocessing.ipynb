{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06ac93c9",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "This is a neat script that downloads UniProt data and extracts subcellular localization annotations for each protein. We'll use this data to later extract features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43b080",
   "metadata": {},
   "source": [
    "## Shell script\n",
    "\n",
    "This script downloads the UniProt data and decompresses it. Takes around 3 minutes to run. We later extract the sequences and re-write them as FASTA ourselves; however, you are more than welcome to use the original FASTA files if you prefer using:\n",
    "\n",
    "```bash\n",
    "wget ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\n",
    "gunzip uniprot_sprot.fasta.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af20833",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "mkdir -p data/raw\n",
    "cd data/raw\n",
    "\n",
    "echo \"Downloading UniProtKB/Swiss-Prot...\"\n",
    "wget -q ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.dat.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd612e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"Decompressing...\"\n",
    "gunzip -f data/raw/uniprot_sprot.dat.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78677033",
   "metadata": {},
   "source": [
    "## Python module\n",
    "\n",
    "The following Python module contains the code that processes the UniProt data and extracts subcellular localization annotations for each protein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b134a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mapexploc.preprocessing import extract_protein_data\n",
    "import pandas as pd\n",
    "from Bio import SwissProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b499730",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DAT = \"data/raw/uniprot_sprot.dat\"\n",
    "INPUT_FASTA = \"data/processed/nonredundant.fasta\"\n",
    "\n",
    "OUTPUT_ANN = \"data/processed/annotations.csv\"\n",
    "OUTPUT_FASTA = \"data/processed/filtered.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df244990",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [\n",
    "    OUTPUT_ANN,\n",
    "    OUTPUT_FASTA,\n",
    "]:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25719cf9",
   "metadata": {},
   "source": [
    "We manually exclude a few terms that indicates non-experimental evidence or are not specific enough to be useful for localization prediction. Additionally, we map some specific biological locations to more general terms to reduce the number of unique labels. This should be extended as needed, as this list is far from exhaustive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08fed63",
   "metadata": {},
   "source": [
    "We exclude multi-compartment entries for this iteration. Single-label classifiers canâ€™t handle proteins annotated to two or more compartments - splitting multi-labels naively can inflate class counts and introduce bias.\n",
    "\n",
    "Some more considerations:\n",
    "\n",
    "+ Performance benchmarks (speed, memory) become harder to interpret when outputs are vectors rather than one label.\n",
    "+ Decision-support tools often struggle to map multi-compartment calls to single ACMG evidence codes.\n",
    "+ Rare two-compartment combinations will have very few examples. This can undermine learning.\n",
    "\n",
    "Future iterations can revisit multi-label approaches once the single-label pipeline produces a good benchmark, as clinically, mis- or multi-localization can be disease-relevant, and it is always good to retain them and preserve for downstream pathway analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(OUTPUT_ANN):\n",
    "    df = pd.read_csv(OUTPUT_ANN)\n",
    "    print(f\"Loaded existing annotations from {OUTPUT_ANN}\")\n",
    "else:\n",
    "    print(f\"No existing annotations found, extracting from {INPUT_DAT}\")\n",
    "    print(\"Extracting protein data...\")\n",
    "    protein_data = extract_protein_data(INPUT_DAT)\n",
    "\n",
    "    df = pd.DataFrame(protein_data)\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "    df.to_csv(OUTPUT_ANN, index=False)\n",
    "    print(f\"\\nWrote annotations to {OUTPUT_ANN}!\")\n",
    "    print(f\"DataFrame saved with {len(df)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b680663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDataset statistics:\")\n",
    "print(f\"Total entries: {len(df)}\")\n",
    "print(f\"Unique localizations: {df['localization'].nunique()}\")\n",
    "print(f\"Average sequence length: {df['sequence'].str.len().mean():.1f}\")\n",
    "\n",
    "print(\"\\nTop 10 most common localizations:\")\n",
    "print(df[\"localization\"].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac088c5d",
   "metadata": {},
   "source": [
    "The following code is for debugging purposes and can be removed. It simply saves the full localization distribution to a text file for later analysis. This is useful to understand the distribution of localizations in the dataset, and to ensure that the filtering is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/localization_distribution.txt\", \"w\") as f:\n",
    "    f.write(\"Full localization distribution:\\n\")\n",
    "    f.write(df[\"localization\"].value_counts().to_string())\n",
    "    print(\n",
    "        \"\\nFull localization distribution saved to data/localization_distribution.txt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923349a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization: convert string columns to categorical to save memory\n",
    "df['entry_name'] = df['entry_name'].astype('category')\n",
    "df['localization'] = df['localization'].astype('category')\n",
    "\n",
    "print(f\"Optimized memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a546fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nQuick data exploration:\")\n",
    "print(\"Sequence length distribution:\")\n",
    "print(df['sequence'].str.len().describe())\n",
    "\n",
    "print(\"\\nData quality checks:\")\n",
    "short_seqs = (df['sequence'].str.len() < 50).sum()\n",
    "long_seqs = (df['sequence'].str.len() > 2000).sum()\n",
    "print(f\"Short sequences (<50 AA): {short_seqs}\")\n",
    "print(f\"Long sequences (>2000 AA): {long_seqs}\")\n",
    "\n",
    "print(\"\\nSample of processed data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ea627",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_FASTA, \"w\") as out:\n",
    "    for _, row in df.iterrows():\n",
    "        header = f\">{row['entry_name']}|{row['localization']}\"\n",
    "        seq = row[\"sequence\"]\n",
    "        out.write(f\"{header}\\n\")\n",
    "\n",
    "        for i in range(0, len(seq), 80):\n",
    "            out.write(seq[i : i + 80] + \"\\n\")\n",
    "\n",
    "print(f\"Wrote FASTA to {OUTPUT_FASTA}\")\n",
    "print(f\"Generated {len(df)} sequences in FASTA format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f62b1",
   "metadata": {},
   "source": [
    "We now use [CD-HIT](https://github.com/weizhongli/cdhit/) to cluster the UniProtKB/Swiss-Prot FASTA file at 90% sequence identity, which is a common practice to reduce redundancy in protein datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c0036",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "INPUT_FASTA=\"data/processed/filtered.fasta\"\n",
    "OUTPUT_FASTA=\"data/processed/nonredundant.fasta\"\n",
    "THREADS=4\n",
    "\n",
    "echo \"Running CD-HIT...\"\n",
    "cd-hit -i \"$INPUT_FASTA\" \\\n",
    "       -o \"$OUTPUT_FASTA\" \\\n",
    "       -c 0.90 -n 5 \\\n",
    "       -M 16000 -T $THREADS\n",
    "\n",
    "if command -v cd-hit &> /dev/null; then\n",
    "    echo \"CD-HIT is installed, proceeding with clustering...\"\n",
    "    cd-hit -i \"$INPUT_FASTA\" \\\n",
    "       -o \"$OUTPUT_FASTA\" \\\n",
    "       -c 0.90 -n 5 \\\n",
    "       -M 16000 -T $THREADS\n",
    "    echo \"Clustering completed, nonredundant FASTA at $OUTPUT_FASTA\"\n",
    "else\n",
    "    echo \"CD-HIT is not installed. Please install it to perform clustering.\"\n",
    "fi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eslp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
